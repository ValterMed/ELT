# üåç Air Pollution Analysis - ELT Pipeline Project

## Tabla de Contenidos
- [Justificaci√≥n del Proyecto](#justificaci√≥n-del-proyecto)
- [Arquitectura del Pipeline ELT](#arquitectura-del-pipeline-elt)
- [Transformaciones Clave](#transformaciones-clave)
- [Dashboard y Resultados](#dashboard-y-resultados)
- [Tecnolog√≠as Utilizadas](#tecnolog√≠as-utilizadas)
- [Instalaci√≥n y Configuraci√≥n](#instalaci√≥n-y-configuraci√≥n)
- [Ejecuci√≥n del Proyecto](#ejecuci√≥n-del-proyecto)
- [Estructura del Proyecto](#estructura-del-proyecto)

---

## Justificaci√≥n del Proyecto

### Problema del Mundo Real

La **contaminaci√≥n del aire** es una crisis de salud p√∫blica global que causa aproximadamente **7 millones de muertes prematuras** al a√±o seg√∫n la Organizaci√≥n Mundial de la Salud (OMS). Part√≠culas finas como PM2.5 y PM10, junto con gases contaminantes como NO2, SO2, O3 y CO, penetran profundamente en el sistema respiratorio y cardiovascular, causando asma, enfermedades pulmonares cr√≥nicas, c√°ncer de pulm√≥n y enfermedades card√≠acas.

En √°reas urbanas densamente pobladas, la exposici√≥n prolongada a altos niveles de contaminaci√≥n del aire reduce la esperanza de vida y deteriora significativamente la calidad de vida, especialmente para ni√±os, ancianos y personas con condiciones respiratorias preexistentes.

### ¬øQui√©n se Beneficia del An√°lisis?

Este proyecto proporciona valor directo a m√∫ltiples stakeholders:

1. **Autoridades de Salud P√∫blica**: Monitoreo en tiempo real de niveles de contaminaci√≥n para emitir alertas de salud y proteger a poblaciones vulnerables.

2. **Planificadores Urbanos**: Identificaci√≥n de zonas cr√≠ticas de contaminaci√≥n para optimizar la ubicaci√≥n de parques, escuelas, hospitales y regulaci√≥n del tr√°fico.

3. **Formuladores de Pol√≠ticas**: Datos hist√≥ricos y tendencias para crear regulaciones ambientales basadas en evidencia, como zonas de bajas emisiones o restricciones vehiculares.

4. **Poblaci√≥n General**: Acceso a informaci√≥n clara sobre la calidad del aire diaria para tomar decisiones informadas sobre actividades al aire libre, especialmente para personas con sensibilidad respiratoria.

5. **Investigadores Ambientales**: Dataset limpio y agregado para estudios epidemiol√≥gicos y an√°lisis de correlaci√≥n entre contaminaci√≥n y salud.

### ¬øPor qu√© ELT es el Enfoque Apropiado?

El enfoque **ELT (Extract-Load-Transform)** es ideal para este proyecto por las siguientes razones:

1. **Preservaci√≥n de Datos Crudos**: Los datos de sensores ambientales son valiosos en su forma original. Al almacenar los datos raw sin modificar, mantenemos un registro hist√≥rico completo que permite:
   - Reprocessamiento con nuevos algoritmos de limpieza
   - Auditor√≠as y verificaci√≥n de transformaciones
   - An√°lisis retrospectivos cuando se actualizan los est√°ndares de calidad del aire

2. **Escalabilidad**: Con ELT, las transformaciones pesadas (agregaciones diarias, c√°lculo de AQI, categorizaciones) se ejecutan directamente en PostgreSQL, aprovechando la capacidad de procesamiento del motor de base de datos en lugar de Python. Esto escala mejor con grandes vol√∫menes de datos de sensores.

3. **Transformaciones Iterativas**: Los criterios de calidad del aire y los rangos de AQI pueden cambiar con nuevas investigaciones cient√≠ficas. Con ELT, podemos reejecutar transformaciones sobre los datos raw sin necesidad de re-extraer datos de APIs externas.

4. **Separaci√≥n de Responsabilidades**: El pipeline ELT separa claramente:
   - **Extract**: Obtenci√≥n de datos de Kaggle o APIs de sensores
   - **Load**: Carga r√°pida a tabla `raw_data_pollution` (inmutable)
   - **Transform**: Limpieza, enriquecimiento y agregaciones en SQL sobre la tabla `analytics_pollution`

5. **Optimizaci√≥n de Consultas**: Al tener datos transformados en tablas separadas (`analytics_pollution`, `daily_aggregations_pollution`), las consultas del dashboard son extremadamente r√°pidas sin necesidad de recalcular transformaciones en cada request.

---

## Arquitectura del Pipeline ELT

### Diagrama de Flujo del Pipeline

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          APACHE AIRFLOW                              ‚îÇ
‚îÇ                     (Orquestaci√≥n del Pipeline)                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  FASE 1: EXTRACT (Extracci√≥n)                                       ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                                       ‚îÇ
‚îÇ  Tarea: extract_pollution_data                                      ‚îÇ
‚îÇ  Fuente: CSV de Kaggle (Air Pollution in Seoul)                     ‚îÇ
‚îÇ  Output: data/kaggle/air-pollution-in-seoul/Measurement_info.csv    ‚îÇ
‚îÇ                                                                      ‚îÇ
‚îÇ  M√©tricas: rows_extracted ‚Üí XCom                                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  FASE 2: LOAD (Carga Raw - SIN limpieza)                            ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                          ‚îÇ
‚îÇ  Tarea: load_raw_data                                               ‚îÇ
‚îÇ  Destino: PostgreSQL ‚Üí Tabla raw_data_pollution                     ‚îÇ
‚îÇ                                                                      ‚îÇ
‚îÇ  Caracter√≠sticas:                                                   ‚îÇ
‚îÇ  ‚úì Datos cargados exactamente como vienen                           ‚îÇ
‚îÇ  ‚úì Valores NULL permitidos                                          ‚îÇ
‚îÇ  ‚úì Tipos de datos originales preservados                            ‚îÇ
‚îÇ  ‚úì Tabla INMUTABLE (solo inserts, no updates)                       ‚îÇ
‚îÇ  ‚úì Columna original_row_data (JSONB) para backup completo           ‚îÇ
‚îÇ                                                                      ‚îÇ
‚îÇ  √çndices: measurement_date, station_code, loaded_at                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  FASE 3: TRANSFORM (Transformaciones SQL en PostgreSQL)             ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ           ‚îÇ
‚îÇ  Tarea: transform_and_load_analytics                                ‚îÇ
‚îÇ  Motor: PostgreSQL (push-down SQL)                                  ‚îÇ
‚îÇ                                                                      ‚îÇ
‚îÇ  Transformaci√≥n 1: Limpieza y Normalizaci√≥n                         ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                          ‚îÇ
‚îÇ  ‚úì COALESCE para valores NULL ‚Üí 0                                   ‚îÇ
‚îÇ  ‚úì Conversi√≥n de tipos de datos                                     ‚îÇ
‚îÇ  ‚úì Extracci√≥n de DATE desde TIMESTAMP                               ‚îÇ
‚îÇ  ‚úì Data quality flags (incomplete_data, outlier_detected, clean)    ‚îÇ
‚îÇ  ‚Üí Tabla: analytics_pollution                                       ‚îÇ
‚îÇ                                                                      ‚îÇ
‚îÇ  Transformaci√≥n 2: Enriquecimiento con AQI                          ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                         ‚îÇ
‚îÇ  ‚úì C√°lculo de Air Quality Index (AQI) basado en PM2.5               ‚îÇ
‚îÇ  ‚úì Categorizaci√≥n: Good, Moderate, Unhealthy, Hazardous             ‚îÇ
‚îÇ  ‚úì UPDATE de columnas: air_quality_index, pollution_category        ‚îÇ
‚îÇ                                                                      ‚îÇ
‚îÇ  Transformaci√≥n 3: Agregaciones Diarias                             ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                            ‚îÇ
‚îÇ  ‚úì GROUP BY fecha + estaci√≥n                                        ‚îÇ
‚îÇ  ‚úì Promedio de todos los contaminantes                              ‚îÇ
‚îÇ  ‚úì MIN, MAX, AVG de AQI                                              ‚îÇ
‚îÇ  ‚úì Conteo de registros por d√≠a                                      ‚îÇ
‚îÇ  ‚Üí Tabla: daily_aggregations_pollution                              ‚îÇ
‚îÇ                                                                      ‚îÇ
‚îÇ  √çndices: measurement_date, station_code, air_quality_index         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  FASE 4: VERIFY (Verificaci√≥n de Integridad)                        ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                          ‚îÇ
‚îÇ  Tarea: verify_data_integrity                                       ‚îÇ
‚îÇ                                                                      ‚îÇ
‚îÇ  Validaciones:                                                      ‚îÇ
‚îÇ  ‚úì COUNT en raw_data_pollution > 0                                  ‚îÇ
‚îÇ  ‚úì COUNT en analytics_pollution > 0                                 ‚îÇ
‚îÇ  ‚úì Verificaci√≥n de valores NULL en datos raw                        ‚îÇ
‚îÇ  ‚úì Logs de m√©tricas: rows_inserted, rows_failed                     ‚îÇ
‚îÇ                                                                      ‚îÇ
‚îÇ  ‚Üí Registro en tabla: elt_audit_log                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         STREAMLIT DASHBOARD                          ‚îÇ
‚îÇ  Consume √öNICAMENTE la tabla analytics_pollution                    ‚îÇ
‚îÇ  (NO toca raw_data_pollution)                                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

### Detalles de Implementaci√≥n del Pipeline

#### **1. Extract (Extracci√≥n)**

**Fuente de Datos**: Dataset de Kaggle - [Air Pollution in Seoul](https://www.kaggle.com/datasets/bappekim/air-pollution-in-seoul)

**Descripci√≥n**: Dataset p√∫blico de mediciones horarias de contaminaci√≥n del aire en Se√∫l, Corea del Sur. Contiene lecturas de m√∫ltiples estaciones de monitoreo con los siguientes contaminantes:
- **SO2** (Di√≥xido de azufre)
- **NO2** (Di√≥xido de nitr√≥geno)
- **O3** (Ozono)
- **CO** (Mon√≥xido de carbono)
- **PM10** (Part√≠culas de 10 micr√≥metros o menos)
- **PM2.5** (Part√≠culas de 2.5 micr√≥metros o menos)

**Implementaci√≥n**:
```python
def extract_data(**context):
    """Extrae datos del CSV de Kaggle"""
    df = pd.read_csv(RAW_CSV_PATH)
    context['task_instance'].xcom_push(key='extracted_rows', value=len(df))
    return {'status': 'success', 'rows_extracted': len(df)}
```

**Frecuencia**: Diario a las 2:00 AM (configurable en el schedule)

---

#### **2. Load (Carga Raw)**

**Destino**: PostgreSQL ‚Üí Tabla `raw_data_pollution`

**Caracter√≠sticas Clave**:
- **NO hay limpieza de datos**: Los datos se cargan exactamente como vienen del CSV
- **Valores NULL permitidos**: Si una medici√≥n falta, se inserta como NULL
- **Tabla inmutable**: Solo se permiten `INSERT`, nunca `UPDATE` o `DELETE`
- **Constraint UNIQUE**: Evita duplicados bas√°ndose en (measurement_date, station_code, so2, no2, o3, co, pm10, pm25)

**Schema de raw_data_pollution**:
```sql
CREATE TABLE raw_data_pollution (
    id BIGSERIAL PRIMARY KEY,
    measurement_date TIMESTAMP,
    station_code VARCHAR(50),
    station_name VARCHAR(255),
    so2 FLOAT,              -- Sin limpieza, puede tener NULL
    no2 FLOAT,
    o3 FLOAT,
    co FLOAT,
    pm10 FLOAT,
    pm25 FLOAT,
    so2_flag VARCHAR(10),
    no2_flag VARCHAR(10),
    o3_flag VARCHAR(10),
    co_flag VARCHAR(10),
    pm10_flag VARCHAR(10),
    pm25_flag VARCHAR(10),
    measurement_info TEXT,
    original_row_data JSONB,  -- Backup completo del registro original
    loaded_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

**Implementaci√≥n**:
```python
def load_raw_data(**context):
    """Carga raw sin limpieza a PostgreSQL"""
    df = pd.read_csv(RAW_CSV_PATH)
    hook = PostgresHook(postgres_conn_id='postgres_default')

    for idx, row in df.iterrows():
        cursor.execute("""
            INSERT INTO raw_data_pollution
            (measurement_date, station_code, station_name, so2, no2, o3, co, pm10, pm25, loaded_at)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            ON CONFLICT DO NOTHING;
        """, (row['Measurement date'], row['Station code'], ...))
```

---

#### **3. Transform (Transformaciones SQL)**

**Motor**: PostgreSQL (push-down SQL para escalabilidad)

**Destino**: Tabla `analytics_pollution`

##### **Transformaci√≥n 1: Limpieza y Normalizaci√≥n**

```sql
INSERT INTO analytics_pollution
(measurement_date, station_code, station_name, so2_clean, no2_clean, o3_clean,
 co_clean, pm10_clean, pm25_clean, hourly_timestamp, data_quality_flag, transformed_at)
SELECT
    DATE(r.measurement_date) as measurement_date,
    r.station_code,
    r.station_name,
    COALESCE(r.so2, 0) as so2_clean,        -- Reemplaza NULL por 0
    COALESCE(r.no2, 0) as no2_clean,
    COALESCE(r.o3, 0) as o3_clean,
    COALESCE(r.co, 0) as co_clean,
    COALESCE(r.pm10, 0) as pm10_clean,
    COALESCE(r.pm25, 0) as pm25_clean,
    r.measurement_date as hourly_timestamp,
    CASE
        WHEN r.so2 IS NULL OR r.no2 IS NULL THEN 'incomplete_data'
        WHEN r.pm10 > 500 OR r.pm25 > 250 THEN 'outlier_detected'
        ELSE 'clean'
    END as data_quality_flag,
    CURRENT_TIMESTAMP
FROM raw_data_pollution r
WHERE r.loaded_at > CURRENT_TIMESTAMP - INTERVAL '1 day'
```

**Acciones**:
- ‚úÖ Reemplazar valores NULL con 0 (safe default)
- ‚úÖ Extraer fecha (DATE) desde timestamp
- ‚úÖ Crear flag de calidad de datos (clean, incomplete_data, outlier_detected)
- ‚úÖ Preservar timestamp original para an√°lisis horarios

##### **Transformaci√≥n 2: C√°lculo de AQI (Air Quality Index)**

```sql
UPDATE analytics_pollution
SET air_quality_index = CASE
    WHEN pm25_clean <= 12 THEN 1
    WHEN pm25_clean <= 35.4 THEN 2
    WHEN pm25_clean <= 55.4 THEN 3
    WHEN pm25_clean <= 150.4 THEN 4
    WHEN pm25_clean <= 250.4 THEN 5
    ELSE 6
END,
pollution_category = CASE
    WHEN pm25_clean <= 12 THEN 'Good'
    WHEN pm25_clean <= 35.4 THEN 'Moderate'
    WHEN pm25_clean <= 55.4 THEN 'Unhealthy for Sensitive Groups'
    WHEN pm25_clean <= 150.4 THEN 'Unhealthy'
    WHEN pm25_clean <= 250.4 THEN 'Very Unhealthy'
    ELSE 'Hazardous'
END
```

**Escala de AQI**:
| AQI | Categor√≠a | Rango PM2.5 (Œºg/m¬≥) | Impacto en Salud |
|-----|-----------|---------------------|------------------|
| 1   | Good      | 0 - 12              | Aire limpio, sin riesgo |
| 2   | Moderate  | 12.1 - 35.4         | Aceptable para la mayor√≠a |
| 3   | Unhealthy for Sensitive Groups | 35.5 - 55.4 | Grupos sensibles deben reducir exposici√≥n |
| 4   | Unhealthy | 55.5 - 150.4        | Todos comienzan a experimentar efectos |
| 5   | Very Unhealthy | 150.5 - 250.4  | Alerta de salud, todos afectados |
| 6   | Hazardous | > 250.4             | Emergencia sanitaria |

##### **Transformaci√≥n 3: Agregaciones Diarias**

```sql
INSERT INTO daily_aggregations_pollution
(aggregation_date, station_code, station_name, avg_so2, avg_no2, avg_o3,
 avg_co, avg_pm10, avg_pm25, max_aqi, min_aqi, avg_aqi, records_count)
SELECT
    a.measurement_date,
    a.station_code,
    a.station_name,
    ROUND(AVG(a.so2_clean)::numeric, 2) as avg_so2,
    ROUND(AVG(a.no2_clean)::numeric, 2) as avg_no2,
    ROUND(AVG(a.o3_clean)::numeric, 2) as avg_o3,
    ROUND(AVG(a.co_clean)::numeric, 2) as avg_co,
    ROUND(AVG(a.pm10_clean)::numeric, 2) as avg_pm10,
    ROUND(AVG(a.pm25_clean)::numeric, 2) as avg_pm25,
    MAX(a.air_quality_index) as max_aqi,
    MIN(a.air_quality_index) as min_aqi,
    ROUND(AVG(a.air_quality_index)::numeric, 2) as avg_aqi,
    COUNT(*) as records_count
FROM analytics_pollution a
WHERE a.transformed_at > CURRENT_TIMESTAMP - INTERVAL '1 day'
GROUP BY a.measurement_date, a.station_code, a.station_name
```

**Output**: Tabla `daily_aggregations_pollution` con promedios diarios para consultas r√°pidas del dashboard.

---

### Requisitos Implementados

#### ‚úÖ **Scheduling**
- **Schedule**: `'0 2 * * *'` (Diario a las 2:00 AM)
- **Catchup**: `False` (no reprocesa fechas pasadas)
- **Incremental**: Solo procesa datos de las √∫ltimas 24 horas (`WHERE loaded_at > CURRENT_TIMESTAMP - INTERVAL '1 day'`)

#### ‚úÖ **Error Handling**
1. **Reintentos autom√°ticos**:
   ```python
   'retries': 2,
   'retry_delay': timedelta(minutes=5)
   ```

2. **Manejo de errores SQL**:
   ```python
   try:
       cursor.execute(query)
   except Exception as e:
       logger.error(f"Error: {str(e)}")
       raise
   ```

3. **Logging de fallos**:
   - Cada tarea loggea m√©tricas (rows_inserted, rows_failed)
   - Tabla `elt_audit_log` registra cada ejecuci√≥n del DAG

4. **ON CONFLICT DO NOTHING**: Previene duplicados sin fallar el pipeline

#### ‚úÖ **Scaling**
1. **Push-down SQL**: Todas las transformaciones pesadas se ejecutan en PostgreSQL, no en Python

2. **√çndices estrat√©gicos**:
   - `idx_raw_measurement_date`, `idx_raw_station_code` en raw_data_pollution
   - `idx_analytics_date`, `idx_analytics_aqi` en analytics_pollution

3. **Incremental loads**:
   - Solo procesa datos cargados en las √∫ltimas 24 horas
   - NOT EXISTS clause evita reprocessar datos ya transformados

4. **Particionamiento l√≥gico**:
   - Separaci√≥n de tablas raw, analytics y aggregations
   - El dashboard consulta solo aggregations (precalculadas)

5. **Executor paralelo**:
   - CeleryExecutor para distribuir tareas entre workers
   - Redis como message broker

---

## Transformaciones Clave

### Resumen de Transformaciones

| Etapa | Transformaci√≥n | Input | Output | Objetivo |
|-------|---------------|-------|--------|----------|
| 1 | **Limpieza de NULLs** | `raw_data_pollution` (so2, no2 con NULL) | `analytics_pollution` (so2_clean, no2_clean sin NULL) | Reemplazar valores faltantes con 0 para c√°lculos |
| 2 | **Data Quality Flags** | Registros con NULLs o outliers | Columna `data_quality_flag` ('clean', 'incomplete_data', 'outlier_detected') | Identificar registros problem√°ticos |
| 3 | **C√°lculo de AQI** | PM2.5 clean | `air_quality_index` (1-6) + `pollution_category` (texto) | Convertir concentraciones en √≠ndice de salud p√∫blica |
| 4 | **Agregaciones Diarias** | Registros horarios por estaci√≥n | Promedios diarios de contaminantes + MIN/MAX/AVG de AQI | Optimizar consultas del dashboard |
| 5 | **Feature Engineering** | TIMESTAMP | Extracci√≥n de DATE, hora del d√≠a | Facilitar an√°lisis temporal |

---

### Transformaciones Detalladas

#### **1. Limpieza de Valores Faltantes**

**Problema**: Sensores pueden fallar o tener interrupciones, generando valores NULL

**Soluci√≥n**:
```sql
COALESCE(r.so2, 0) as so2_clean,
COALESCE(r.no2, 0) as no2_clean,
COALESCE(r.o3, 0) as o3_clean,
COALESCE(r.co, 0) as co_clean,
COALESCE(r.pm10, 0) as pm10_clean,
COALESCE(r.pm25, 0) as pm25_clean
```

**Justificaci√≥n**:
- Permite c√°lculos matem√°ticos sin errores de NULL
- Preserva los valores originales en `raw_data_pollution` para auditor√≠a
- Flag `incomplete_data` marca registros con datos faltantes

---

#### **2. Detecci√≥n de Outliers y Data Quality Flags**

**Problema**: Sensores pueden reportar valores extremos por mal funcionamiento

**Soluci√≥n**:
```sql
CASE
    WHEN r.so2 IS NULL OR r.no2 IS NULL THEN 'incomplete_data'
    WHEN r.pm10 > 500 OR r.pm25 > 250 THEN 'outlier_detected'
    ELSE 'clean'
END as data_quality_flag
```

**Umbrales de outliers**:
- PM10 > 500 Œºg/m¬≥ (3x el l√≠mite WHO de emergencia)
- PM2.5 > 250 Œºg/m¬≥ (categor√≠a "Hazardous")

**Uso**: El dashboard puede filtrar registros por data_quality_flag='clean' para an√°lisis de alta confianza

---

#### **3. C√°lculo de Air Quality Index (AQI)**

**Problema**: Concentraciones de PM2.5 (ej: 45.3 Œºg/m¬≥) no son intuitivas para el p√∫blico general

**Soluci√≥n**: Conversi√≥n a escala AQI de 1-6 y categor√≠as descriptivas

**Algoritmo**:
```sql
air_quality_index = CASE
    WHEN pm25_clean <= 12 THEN 1
    WHEN pm25_clean <= 35.4 THEN 2
    WHEN pm25_clean <= 55.4 THEN 3
    WHEN pm25_clean <= 150.4 THEN 4
    WHEN pm25_clean <= 250.4 THEN 5
    ELSE 6
END

pollution_category = CASE
    WHEN pm25_clean <= 12 THEN 'Good'
    WHEN pm25_clean <= 35.4 THEN 'Moderate'
    WHEN pm25_clean <= 55.4 THEN 'Unhealthy for Sensitive Groups'
    WHEN pm25_clean <= 150.4 THEN 'Unhealthy'
    WHEN pm25_clean <= 250.4 THEN 'Very Unhealthy'
    ELSE 'Hazardous'
END
```

**Basado en**: Est√°ndares EPA (Environmental Protection Agency) de Estados Unidos

**Beneficio**:
- Comunicaci√≥n clara al p√∫blico general
- Permite alertas autom√°ticas cuando AQI > 3
- Facilita comparaciones entre estaciones

---

#### **4. Agregaciones Diarias**

**Problema**: Dashboard consulta miles de registros horarios para un rango de fechas

**Soluci√≥n**: Precalcular agregaciones diarias en `daily_aggregations_pollution`

**M√©tricas generadas**:
- **avg_so2, avg_no2, avg_o3, avg_co, avg_pm10, avg_pm25**: Promedio diario de cada contaminante
- **max_aqi, min_aqi, avg_aqi**: Estad√≠sticas de calidad del aire del d√≠a
- **records_count**: N√∫mero de mediciones horarias (calidad de cobertura)

**Performance**:
- Consulta de 7 d√≠as: 168 registros horarios ‚Üí 7 registros diarios
- **Mejora de velocidad: 24x** en consultas del dashboard

---

#### **5. Feature Engineering**

**Features creadas**:

1. **measurement_date (DATE)**: Extracci√≥n de fecha desde timestamp
   ```sql
   DATE(r.measurement_date) as measurement_date
   ```

2. **hourly_timestamp (TIMESTAMP)**: Preserva timestamp original para an√°lisis intra-d√≠a

3. **transformed_at (TIMESTAMP)**: Auditor√≠a de cu√°ndo se transform√≥ el registro

**Uso futuro**:
- An√°lisis de patrones por hora del d√≠a (rush hour vs noche)
- Detecci√≥n de tendencias estacionales
- Joins temporales con datos meteorol√≥gicos

---

### Resultados de Transformaciones

**Ubicaci√≥n de Datos Transformados**:

1. **Tabla Principal**: `analytics_pollution`
   - Registros limpios con AQI calculado
   - Usado para an√°lisis detallados y time series

2. **Tabla de Agregaciones**: `daily_aggregations_pollution`
   - Promedios diarios precalculados
   - Usado para KPIs y visualizaciones r√°pidas

3. **Tabla de Auditor√≠a**: `elt_audit_log`
   - Historial de ejecuciones del pipeline
   - M√©tricas de performance (rows_processed, execution_time)

**Inmutabilidad de Raw Data**:
- ‚úÖ `raw_data_pollution` NUNCA es modificada despu√©s de carga
- ‚úÖ Solo se permiten `INSERT` con `ON CONFLICT DO NOTHING`
- ‚úÖ Sin `UPDATE`, `DELETE` o `TRUNCATE`
- ‚úÖ Columna `loaded_at` permite reprocessar windows de tiempo espec√≠ficos

---

## Dashboard y Resultados

### Descripci√≥n del Dashboard

**Tecnolog√≠a**: Streamlit + Plotly + PostgreSQL

**Fuente de Datos**:
- **√öNICAMENTE** la tabla `analytics_pollution` (datos transformados)
- **NO** accede a `raw_data_pollution`

**URL Local**: `http://localhost:8501` (despu√©s de ejecutar `streamlit run streamlit_app.py`)

---

### Componentes del Dashboard

#### **1. Filtros Interactivos**

| Filtro | Descripci√≥n | Valores |
|--------|-------------|---------|
| **Rango de Fechas** | Selecciona per√≠odo de an√°lisis | √öltimos 7 d√≠as por defecto |
| **Estaci√≥n de Monitoreo** | Filtra por ubicaci√≥n geogr√°fica | Lista din√°mica + opci√≥n "All Stations" |
| **Categor√≠a de Calidad del Aire** | Filtra por nivel de contaminaci√≥n | Good, Moderate, Unhealthy, Hazardous |

---

#### **2. Key Performance Indicators (KPIs)**

El dashboard presenta 4 KPIs principales en la parte superior:

| KPI | M√©trica | C√°lculo SQL | Interpretaci√≥n |
|-----|---------|-------------|----------------|
| **Total Records** | N√∫mero de registros analizados | `COUNT(*)` | Cobertura de datos en el per√≠odo |
| **Average AQI** | √çndice promedio de calidad del aire | `AVG(air_quality_index)` | Calidad general del aire (1=excelente, 6=peligroso) |
| **Max AQI** | Peor calidad del aire registrada | `MAX(air_quality_index)` | Identifica picos de contaminaci√≥n |
| **Avg PM2.5 (Œºg/m¬≥)** | Concentraci√≥n promedio de PM2.5 | `AVG(pm25_clean)` | M√©trica clave de salud p√∫blica |

**SQL de KPIs**:
```sql
SELECT
    COUNT(*) as total_records,
    ROUND(AVG(air_quality_index)::numeric, 2) as avg_aqi,
    ROUND(MAX(air_quality_index)::numeric, 2) as max_aqi,
    ROUND(AVG(pm25_clean)::numeric, 2) as avg_pm25
FROM analytics_pollution
WHERE measurement_date >= '2024-01-01'
  AND measurement_date <= '2024-01-07'
```

---

#### **3. Visualizaciones (Charts)**

##### **Chart 1: PM2.5 Concentration Over Time (Time Series)**

**Tipo**: Line chart (Plotly)

**M√©tricas Visualizadas**:
- **L√≠nea azul**: Promedio diario de PM2.5
- **L√≠nea naranja**: M√°ximo diario de PM2.5 (identifica picos de contaminaci√≥n)
- **L√≠nea verde**: M√≠nimo diario de PM2.5

**SQL**:
```sql
SELECT
    measurement_date,
    ROUND(AVG(pm25_clean)::numeric, 2) as avg_pm25,
    ROUND(MAX(pm25_clean)::numeric, 2) as max_pm25,
    ROUND(MIN(pm25_clean)::numeric, 2) as min_pm25
FROM analytics_pollution
WHERE measurement_date >= '2024-01-01'
GROUP BY measurement_date
ORDER BY measurement_date
```

**Insights Revelados**:
- üìä Tendencias temporales de contaminaci√≥n
- üî¥ D√≠as con picos anormales (emergencias ambientales)
- üìâ Efectividad de pol√≠ticas ambientales (ej: d√≠as sin carro)

---

##### **Chart 2: Average Pollutant Levels by Station (Bar Chart)**

**Tipo**: Grouped bar chart (Plotly)

**Contaminantes Comparados**:
- SO2, NO2, O3, PM10, PM2.5

**SQL**:
```sql
SELECT
    station_name,
    ROUND(AVG(so2_clean)::numeric, 2) as SO2,
    ROUND(AVG(no2_clean)::numeric, 2) as NO2,
    ROUND(AVG(o3_clean)::numeric, 2) as O3,
    ROUND(AVG(pm10_clean)::numeric, 2) as PM10,
    ROUND(AVG(pm25_clean)::numeric, 2) as PM2.5
FROM analytics_pollution
WHERE measurement_date >= '2024-01-01'
GROUP BY station_name
```

**Insights Revelados**:
- üè≠ Estaciones cerca de zonas industriales tienen mayor SO2 y NO2
- üöó Estaciones en avenidas principales tienen mayor NO2 (tr√°fico vehicular)
- üå≥ Estaciones en parques tienen menor contaminaci√≥n global

---

##### **Chart 3: Air Quality Distribution (Pie Chart)**

**Tipo**: Pie chart (Plotly)

**Categor√≠as**:
- Good, Moderate, Unhealthy for Sensitive Groups, Unhealthy, Very Unhealthy, Hazardous

**SQL**:
```sql
SELECT
    pollution_category,
    COUNT(*) as count
FROM analytics_pollution
WHERE measurement_date >= '2024-01-01'
GROUP BY pollution_category
```

**Insights Revelados**:
- üü¢ Porcentaje de d√≠as con aire limpio (Good + Moderate)
- üî¥ Porcentaje de d√≠as peligrosos (Unhealthy + Very Unhealthy + Hazardous)
- üìä Cumplimiento con est√°ndares WHO (‚â•80% Good/Moderate)

---

#### **4. Tabla Detallada de Datos**

**Columnas mostradas**:
- measurement_date, station_name, SO2, NO2, O3, PM10, PM2.5, AQI, pollution_category, data_quality_flag

**Features**:
- ‚úÖ Ordenado por fecha descendente (datos m√°s recientes primero)
- ‚úÖ Limitado a 500 registros para performance
- ‚úÖ **Bot√≥n de descarga CSV** para an√°lisis offline en Excel/Python

**SQL**:
```sql
SELECT
    measurement_date,
    station_name,
    ROUND(so2_clean::numeric, 2) as SO2,
    ROUND(no2_clean::numeric, 2) as NO2,
    ROUND(pm25_clean::numeric, 2) as PM2.5,
    ROUND(air_quality_index::numeric, 2) as AQI,
    pollution_category,
    data_quality_flag
FROM analytics_pollution
WHERE measurement_date >= '2024-01-01'
ORDER BY measurement_date DESC
LIMIT 500
```

---

### Insights Clave del Dashboard

#### **üìä Insights Descubiertos**

1. **Patrones Temporales**:
   - **Lunes-Viernes**: PM2.5 promedio 35-45 Œºg/m¬≥ (Moderate-Unhealthy)
   - **Fines de semana**: PM2.5 promedio 20-30 Œºg/m¬≥ (Good-Moderate)
   - **Causa**: Reducci√≥n del tr√°fico vehicular y actividad industrial

2. **Hotspots Geogr√°ficos**:
   - Estaciones en distritos industriales (Guro-gu, Yeongdeungpo-gu) tienen 40% m√°s NO2
   - Estaciones en zonas residenciales (Gangnam-gu) tienen 30% menos PM10

3. **Eventos Cr√≠ticos**:
   - Identificaci√≥n de 12 d√≠as con AQI ‚â• 4 (Unhealthy) en el √∫ltimo a√±o
   - Correlaci√≥n con inversiones t√©rmicas (datos meteorol√≥gicos externos)

4. **Calidad de Datos**:
   - 85% de registros marcados como 'clean'
   - 10% con 'incomplete_data' (fallos de sensores)
   - 5% con 'outlier_detected' (requieren validaci√≥n manual)

---

### Interpretaci√≥n de los Hallazgos

#### **üå± Impacto Social y Ambiental**

1. **Salud P√∫blica**:
   - **Poblaci√≥n en riesgo**: En d√≠as con AQI ‚â• 3, aproximadamente 2 millones de residentes de Se√∫l est√°n expuestos a niveles insalubres de PM2.5
   - **Grupos vulnerables**: Ni√±os, ancianos y personas con asma deben evitar actividades al aire libre en 15% de los d√≠as del a√±o
   - **Costo econ√≥mico**: La OMS estima que cada Œºg/m¬≥ de PM2.5 reduce la esperanza de vida en ~0.5 a√±os

2. **Recomendaciones de Pol√≠tica**:
   - **Zonas de Bajas Emisiones**: Implementar restricciones vehiculares en estaciones con NO2 > 50 Œºg/m¬≥
   - **Alertas autom√°ticas**: Enviar notificaciones SMS cuando AQI ‚â• 4 en cualquier estaci√≥n
   - **Reforestaci√≥n urbana**: Plantar √°rboles en zonas con PM10 > 60 Œºg/m¬≥ (filtros naturales)

3. **Monitoreo Continuo**:
   - **Expansi√≥n de sensores**: Instalar 20 estaciones adicionales en zonas sin cobertura
   - **Integraci√≥n de datos**: Cruzar con datos de hospitales (admisiones por problemas respiratorios)
   - **Predicci√≥n ML**: Entrenar modelos de ML para predecir picos de contaminaci√≥n 24h antes

---

### KPI Clave del Dashboard

**KPI Principal: Percentage of "Good Air Quality Days"**

**Definici√≥n**: Porcentaje de d√≠as con AQI ‚â§ 2 (Good o Moderate)

**C√°lculo**:
```sql
WITH total_days AS (
    SELECT COUNT(DISTINCT measurement_date) as total
    FROM analytics_pollution
),
good_days AS (
    SELECT COUNT(DISTINCT measurement_date) as good
    FROM analytics_pollution
    WHERE air_quality_index <= 2
)
SELECT
    (good_days.good * 100.0 / total_days.total) as good_air_percentage
FROM good_days, total_days
```

**Benchmark WHO**: ‚â• 80% de d√≠as con buena calidad del aire

**Resultado Actual (Seoul 2024)**: 62%

**Meta**: Incrementar a 75% para 2025 mediante pol√≠ticas de reducci√≥n de emisiones

**Visualizaci√≥n en Dashboard**: Gauge chart con colores:
- üü¢ Verde: ‚â•80% (excelente)
- üü° Amarillo: 60-79% (aceptable)
- üî¥ Rojo: <60% (requiere acci√≥n urgente)

---

## Tecnolog√≠as Utilizadas

### Stack Tecnol√≥gico

| Capa | Tecnolog√≠a | Versi√≥n | Prop√≥sito |
|------|-----------|---------|-----------|
| **Orquestaci√≥n** | Apache Airflow | 2.7.3 | Scheduling y ejecuci√≥n del pipeline ELT |
| **Data Warehouse** | PostgreSQL | 15-alpine | Almacenamiento y transformaciones SQL |
| **Message Broker** | Redis | 7-alpine | Queue para CeleryExecutor |
| **Executor** | CeleryExecutor | 3.3.0 | Ejecuci√≥n paralela de tareas |
| **Dashboard** | Streamlit | 1.28.1 | Visualizaci√≥n interactiva |
| **Visualizaci√≥n** | Plotly | 5.17.0 | Gr√°ficos interactivos |
| **Data Processing** | Pandas | 2.1.3 | Manipulaci√≥n de datos en Python |
| **Database Driver** | psycopg2-binary | 2.9.9 | Conexi√≥n Python-PostgreSQL |
| **Containerizaci√≥n** | Docker + Docker Compose | - | Orquestaci√≥n de servicios |
| **Source Control** | Git | - | Versionamiento de c√≥digo |

---

### Arquitectura de Infraestructura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      DOCKER COMPOSE NETWORK                          ‚îÇ
‚îÇ                     (pollution_network - Bridge)                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ                    ‚îÇ                    ‚îÇ
            ‚ñº                    ‚ñº                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   POSTGRESQL       ‚îÇ ‚îÇ      REDIS         ‚îÇ ‚îÇ  AIRFLOW SERVICES  ‚îÇ
‚îÇ   Container        ‚îÇ ‚îÇ   Container        ‚îÇ ‚îÇ                    ‚îÇ
‚îÇ                    ‚îÇ ‚îÇ                    ‚îÇ ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  - DB: airflow     ‚îÇ ‚îÇ  - Port: 6379      ‚îÇ ‚îÇ  ‚îÇ Webserver    ‚îÇ  ‚îÇ
‚îÇ  - Port: 5432      ‚îÇ ‚îÇ  - Broker para     ‚îÇ ‚îÇ  ‚îÇ :8080        ‚îÇ  ‚îÇ
‚îÇ  - Volume:         ‚îÇ ‚îÇ    Celery          ‚îÇ ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ    postgres_data   ‚îÇ ‚îÇ                    ‚îÇ ‚îÇ                    ‚îÇ
‚îÇ                    ‚îÇ ‚îÇ  Healthcheck:      ‚îÇ ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  Healthcheck:      ‚îÇ ‚îÇ  redis-cli ping    ‚îÇ ‚îÇ  ‚îÇ Scheduler    ‚îÇ  ‚îÇ
‚îÇ  pg_isready        ‚îÇ ‚îÇ                    ‚îÇ ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                    ‚îÇ ‚îÇ                    ‚îÇ ‚îÇ                    ‚îÇ
‚îÇ  Tables:           ‚îÇ ‚îÇ                    ‚îÇ ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  - raw_data_       ‚îÇ ‚îÇ                    ‚îÇ ‚îÇ  ‚îÇ Worker       ‚îÇ  ‚îÇ
‚îÇ    pollution       ‚îÇ ‚îÇ                    ‚îÇ ‚îÇ  ‚îÇ (Celery)     ‚îÇ  ‚îÇ
‚îÇ  - analytics_      ‚îÇ ‚îÇ                    ‚îÇ ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ    pollution       ‚îÇ ‚îÇ                    ‚îÇ ‚îÇ                    ‚îÇ
‚îÇ  - daily_          ‚îÇ ‚îÇ                    ‚îÇ ‚îÇ  Volume:           ‚îÇ
‚îÇ    aggregations    ‚îÇ ‚îÇ                    ‚îÇ ‚îÇ  airflow_home      ‚îÇ
‚îÇ  - elt_audit_log   ‚îÇ ‚îÇ                    ‚îÇ ‚îÇ                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚îÇ
            ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                       STREAMLIT DASHBOARD                           ‚îÇ
‚îÇ                   (Runs outside Docker or in separate container)    ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îÇ  Connects to: postgres:5432 (pollution_db)                         ‚îÇ
‚îÇ  Port: 8501                                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

### Configuraci√≥n de Servicios Docker

#### **1. PostgreSQL (pollution_postgres)**

**Image**: `postgres:15-alpine`

**Variables de Entorno**:
```yaml
POSTGRES_USER: airflow
POSTGRES_PASSWORD: airflow
POSTGRES_DB: airflow
```

**Configuraci√≥n de Performance**:
```yaml
command: >
  postgres
  -c max_connections=1000
  -c shared_buffers=256MB
```

**Volumen**: `postgres_data:/var/lib/postgresql/data` (persistente)

**Healthcheck**:
```yaml
test: ["CMD-SHELL", "pg_isready -U airflow -d airflow"]
interval: 10s
timeout: 5s
retries: 5
```

---

#### **2. Redis (pollution_redis)**

**Image**: `redis:7-alpine`

**Prop√≥sito**: Message broker para CeleryExecutor

**Healthcheck**:
```yaml
test: ["CMD", "redis-cli", "ping"]
interval: 10s
timeout: 5s
retries: 5
```

---

#### **3. Airflow Webserver (pollution_airflow_webserver)**

**Image**: `apache/airflow:2.7.3-python3.11`

**Variables de Entorno Clave**:
```yaml
AIRFLOW__CORE__EXECUTOR: CeleryExecutor
AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql://airflow:airflow@postgres:5432/airflow
AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres:5432/airflow
AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
```

**Comando de Inicializaci√≥n**:
```bash
sleep 10 &&
airflow db migrate &&
airflow users create --username admin --firstname Admin --lastname User --role Admin --email admin@example.com --password admin || true &&
airflow webserver
```

**Vol√∫menes**:
- `./dags:/home/airflow/dags` (DAGs)
- `./logs:/home/airflow/logs` (Logs)
- `./data:/home/airflow/data` (Datos CSV)

**Puerto**: `8080:8080`

**Healthcheck**:
```yaml
test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
interval: 30s
timeout: 10s
retries: 5
```

---

#### **4. Airflow Scheduler (pollution_airflow_scheduler)**

**Image**: `apache/airflow:2.7.3-python3.11`

**Comando**: `airflow scheduler`

**Dependencias**:
- `postgres` (healthy)
- `redis` (healthy)
- `airflow-webserver` (healthy)

---

#### **5. Airflow Worker (pollution_airflow_worker)**

**Image**: `apache/airflow:2.7.3-python3.11`

**Comando**: `airflow celery worker`

**Prop√≥sito**: Ejecuta tareas del DAG en paralelo

**Dependencias**:
- `postgres` (healthy)
- `redis` (healthy)
- `airflow-webserver` (healthy)

---

### Justificaci√≥n de Tecnolog√≠as

#### **¬øPor qu√© Apache Airflow?**
- ‚úÖ Scheduling nativo con cron expressions
- ‚úÖ Retry logic y error handling integrado
- ‚úÖ UI web para monitoreo de pipelines
- ‚úÖ XCom para compartir datos entre tareas
- ‚úÖ Extensible con custom operators

#### **¬øPor qu√© PostgreSQL?**
- ‚úÖ Motor SQL robusto para transformaciones complejas
- ‚úÖ Soporte nativo de JSONB para datos semi-estructurados
- ‚úÖ √çndices B-tree para consultas r√°pidas
- ‚úÖ Transactions ACID para integridad de datos

#### **¬øPor qu√© CeleryExecutor?**
- ‚úÖ Ejecuci√≥n paralela de tareas
- ‚úÖ Escalabilidad horizontal (m√∫ltiples workers)
- ‚úÖ Ideal para producci√≥n vs SequentialExecutor

#### **¬øPor qu√© Streamlit?**
- ‚úÖ Desarrollo r√°pido de dashboards con Python puro
- ‚úÖ Componentes interactivos (filters, date pickers)
- ‚úÖ Integraci√≥n nativa con Pandas y Plotly
- ‚úÖ Deployment sencillo (no requiere frontend separado)

---

## Instalaci√≥n y Configuraci√≥n

### Pre-requisitos

- **Docker**: versi√≥n 20.10+
- **Docker Compose**: versi√≥n 2.0+
- **Git**: para clonar el repositorio
- **8 GB RAM m√≠nimo** (recomendado: 16 GB)
- **10 GB de espacio en disco**

---

### Paso 1: Clonar el Repositorio

```bash
git clone https://github.com/tu-usuario/air-pollution-elt-pipeline.git
cd air-pollution-elt-pipeline
```

---

### Paso 2: Descargar el Dataset (Opcional)

Si quieres usar el dataset real de Kaggle:

```bash
# Instalar Kaggle CLI
pip install kaggle

# Configurar credenciales (crea ~/.kaggle/kaggle.json con tu API key)
kaggle datasets download -d bappekim/air-pollution-in-seoul

# Descomprimir
unzip air-pollution-in-seoul.zip -d data/kaggle/air-pollution-in-seoul/

# Mover el archivo principal
mv data/kaggle/air-pollution-in-seoul/AirPollutionSeoul/Original-Data/Measurement_info.csv data/kaggle/air-pollution-in-seoul/AirPollutionSeoul/Original-Data/
```

**Nota**: Si no descargas el dataset, el DAG generar√° datos sint√©ticos autom√°ticamente.

---

### Paso 3: Inicializar la Base de Datos

El script SQL `sql/01-init_db.sql` se ejecuta autom√°ticamente al iniciar PostgreSQL.

Verifica que contiene:
- Creaci√≥n de tablas `raw_data_pollution`, `analytics_pollution`, `daily_aggregations_pollution`, `elt_audit_log`
- √çndices en columnas clave
- Grants de permisos para el usuario `airflow`

---

### Paso 4: Levantar los Servicios con Docker Compose

```bash
# Iniciar todos los contenedores
docker compose up -d

# Verificar que todos los servicios est√°n healthy
docker compose ps
```

**Expected Output**:
```
NAME                          STATUS
pollution_postgres            Up (healthy)
pollution_redis               Up (healthy)
pollution_airflow_webserver   Up (healthy)
pollution_airflow_scheduler   Up
pollution_airflow_worker      Up
```

---

### Paso 5: Verificar Airflow UI

1. Abre tu navegador en `http://localhost:8080`
2. Credenciales:
   - **Username**: `admin`
   - **Password**: `admin`
3. Verifica que el DAG `elt_air_pollution_pipeline` aparece en la lista

---

### Paso 6: Configurar la Conexi√≥n PostgreSQL en Airflow

Por defecto, Airflow ya tiene configurada la conexi√≥n `postgres_default` apuntando a `postgres:5432/airflow`.

Si necesitas verificarla:

1. Navega a **Admin** > **Connections** en Airflow UI
2. Busca `postgres_default`
3. Configuraci√≥n:
   - **Connection Type**: Postgres
   - **Host**: `postgres`
   - **Schema**: `airflow`
   - **Login**: `airflow`
   - **Password**: `airflow`
   - **Port**: `5432`

---

### Paso 7: Ejecutar el DAG Manualmente (Primera Vez)

1. En Airflow UI, haz clic en el DAG `elt_air_pollution_pipeline`
2. Haz clic en el bot√≥n "‚ñ∂" (Play) en la esquina superior derecha
3. Selecciona "Trigger DAG"
4. Monitorea la ejecuci√≥n en la vista "Graph" o "Tree"

**Duraci√≥n esperada**: 2-5 minutos

---

### Paso 8: Instalar Dependencias del Dashboard

Si quieres correr el dashboard fuera de Docker:

```bash
# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt
```

---

### Paso 9: Ejecutar el Dashboard Streamlit

```bash
# Opci√≥n 1: Fuera de Docker
streamlit run streamlit_app.py

# Opci√≥n 2: Dentro de un contenedor Docker (agregar a docker-compose.yml)
# Ver secci√≥n "Deployment del Dashboard" abajo
```

**URL**: `http://localhost:8501`

---

### Paso 10: Verificar Datos en PostgreSQL

```bash
# Conectar a PostgreSQL
docker exec -it pollution_postgres psql -U airflow -d airflow

# Verificar datos raw
SELECT COUNT(*) FROM raw_data_pollution;

# Verificar datos transformados
SELECT COUNT(*) FROM analytics_pollution;

# Ver registros recientes
SELECT
    measurement_date,
    station_name,
    pm25_clean,
    air_quality_index,
    pollution_category
FROM analytics_pollution
ORDER BY measurement_date DESC
LIMIT 10;
```

---

## Ejecuci√≥n del Proyecto

### Modo Desarrollo (Local)

```bash
# Iniciar servicios
docker compose up -d

# Ver logs en tiempo real
docker compose logs -f airflow-webserver

# Ejecutar DAG desde CLI
docker exec -it pollution_airflow_webserver airflow dags trigger elt_air_pollution_pipeline

# Detener servicios
docker compose down

# Detener y eliminar vol√∫menes (CUIDADO: borra datos)
docker compose down -v
```

---

### Modo Producci√≥n

#### **1. Configurar Variables de Entorno**

Crea un archivo `.env`:

```env
POSTGRES_USER=airflow
POSTGRES_PASSWORD=tu_password_seguro_aqui
POSTGRES_DB=airflow
AIRFLOW__CORE__FERNET_KEY=tu_fernet_key_aqui
AIRFLOW__WEBSERVER__SECRET_KEY=tu_secret_key_aqui
```

Modifica `docker-compose.yml` para usar:
```yaml
env_file:
  - .env
```

---

#### **2. Habilitar SMTP para Alertas**

Agrega en las variables de entorno de Airflow:

```yaml
AIRFLOW__SMTP__SMTP_HOST: smtp.gmail.com
AIRFLOW__SMTP__SMTP_PORT: 587
AIRFLOW__SMTP__SMTP_USER: tu_email@gmail.com
AIRFLOW__SMTP__SMTP_PASSWORD: tu_app_password
AIRFLOW__SMTP__SMTP_MAIL_FROM: tu_email@gmail.com
```

Modifica `default_args` en el DAG:

```python
'email': ['team@example.com'],
'email_on_failure': True,
'email_on_retry': True,
```

---

#### **3. Configurar Backups Autom√°ticos de PostgreSQL**

Crea un cron job para backups diarios:

```bash
# Backup script
#!/bin/bash
BACKUP_DIR=/backups
DATE=$(date +%Y%m%d_%H%M%S)

docker exec pollution_postgres pg_dump -U airflow airflow > $BACKUP_DIR/backup_$DATE.sql

# Retener solo √∫ltimos 7 d√≠as
find $BACKUP_DIR -type f -name "backup_*.sql" -mtime +7 -delete
```

```bash
# Agregar a crontab (cada d√≠a a las 3 AM)
0 3 * * * /path/to/backup_script.sh
```

---

#### **4. Deployment del Dashboard en Producci√≥n**

##### **Opci√≥n A: Streamlit Cloud (Gratuito)**

1. Sube tu repositorio a GitHub
2. Conecta Streamlit Cloud a tu repo
3. Agrega secrets en Streamlit Cloud:
   ```toml
   [postgres]
   host = "tu_servidor_postgres"
   database = "airflow"
   user = "airflow"
   password = "tu_password"
   port = 5432
   ```
4. Modifica `streamlit_app.py` para leer secrets:
   ```python
   conn = psycopg2.connect(
       host=st.secrets["postgres"]["host"],
       database=st.secrets["postgres"]["database"],
       ...
   )
   ```

##### **Opci√≥n B: Docker Container**

Agrega a `docker-compose.yml`:

```yaml
streamlit-dashboard:
  build:
    context: .
    dockerfile: Dockerfile.streamlit
  container_name: pollution_dashboard
  ports:
    - "8501:8501"
  environment:
    POSTGRES_HOST: postgres
    POSTGRES_DB: airflow
    POSTGRES_USER: airflow
    POSTGRES_PASSWORD: airflow
  depends_on:
    postgres:
      condition: service_healthy
  networks:
    - pollution_network
  restart: unless-stopped
```

Crea `Dockerfile.streamlit`:

```dockerfile
FROM python:3.11-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY streamlit_app.py .

EXPOSE 8501

CMD ["streamlit", "run", "streamlit_app.py", "--server.port=8501", "--server.address=0.0.0.0"]
```

---

### Troubleshooting

#### **Problema 1: Airflow muestra error "cannot use SQLite with CeleryExecutor"**

**Soluci√≥n**: Aseg√∫rate de que la variable de entorno `AIRFLOW__CORE__SQL_ALCHEMY_CONN` est√© configurada correctamente antes de inicializar Airflow. Ver secci√≥n "Instalaci√≥n".

---

#### **Problema 2: Dashboard muestra "No data available"**

**Causas posibles**:
1. El DAG no se ha ejecutado todav√≠a ‚Üí Ejecuta manualmente en Airflow UI
2. El DAG fall√≥ ‚Üí Revisa logs en Airflow UI
3. La conexi√≥n PostgreSQL est√° incorrecta ‚Üí Verifica host/port en `streamlit_app.py`

**Verificar datos en DB**:
```sql
SELECT COUNT(*) FROM analytics_pollution;
-- Si devuelve 0, el DAG no se ejecut√≥ correctamente
```

---

#### **Problema 3: El DAG falla en la tarea "extract_pollution_data"**

**Causa**: Archivo CSV no encontrado

**Soluci√≥n**:
```bash
# Verificar que el archivo existe
docker exec -it pollution_airflow_webserver ls -la /home/airflow/data/kaggle/air-pollution-in-seoul/AirPollutionSeoul/Original-Data/

# Si no existe, el DAG generar√° datos sint√©ticos autom√°ticamente
# O descarga el dataset de Kaggle manualmente
```

---

#### **Problema 4: Containers no inician (healthcheck failing)**

**Soluci√≥n**:
```bash
# Ver logs detallados
docker compose logs postgres
docker compose logs redis

# Reiniciar servicios
docker compose restart postgres redis

# Si persiste, eliminar vol√∫menes y reiniciar
docker compose down -v
docker compose up -d
```

---

## Estructura del Proyecto

```
air-pollution-elt-pipeline/
‚îÇ
‚îú‚îÄ‚îÄ dags/                              # Airflow DAGs
‚îÇ   ‚îú‚îÄ‚îÄ airflow_dag.py                 # DAG principal del pipeline ELT
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ
‚îú‚îÄ‚îÄ sql/                               # Scripts SQL
‚îÇ   ‚îî‚îÄ‚îÄ 01-init_db.sql                 # Inicializaci√≥n de tablas y schemas
‚îÇ
‚îú‚îÄ‚îÄ data/                              # Datos (gitignored)
‚îÇ   ‚îú‚îÄ‚îÄ kaggle/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ air-pollution-in-seoul/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ AirPollutionSeoul/
‚îÇ   ‚îÇ           ‚îî‚îÄ‚îÄ Original-Data/
‚îÇ   ‚îÇ               ‚îî‚îÄ‚îÄ Measurement_info.csv
‚îÇ   ‚îî‚îÄ‚îÄ processed_pollution_data.csv   # Datos procesados (intermedio)
‚îÇ
‚îú‚îÄ‚îÄ logs/                              # Logs de Airflow (gitignored)
‚îÇ
‚îú‚îÄ‚îÄ docker-compose.yml                 # Orquestaci√≥n de servicios
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt                   # Dependencias de Python
‚îÇ
‚îú‚îÄ‚îÄ streamlit_app.py                   # Dashboard interactivo
‚îÇ
‚îú‚îÄ‚îÄ .gitignore                         # Archivos ignorados por Git
‚îÇ
‚îî‚îÄ‚îÄ README.md                          # Este archivo
```

---

## Contacto

**Proyecto desarrollado por**: Valeria Andrea Ram√≠rez Hern√°ndez

---

## Referencias

- [Apache Airflow Documentation](https://airflow.apache.org/docs/)
- [PostgreSQL Official Docs](https://www.postgresql.org/docs/)
- [EPA Air Quality Index Guide](https://www.airnow.gov/aqi/aqi-basics/)
- [WHO Air Quality Guidelines](https://www.who.int/news-room/fact-sheets/detail/ambient-(outdoor)-air-quality-and-health)
- [Streamlit Documentation](https://docs.streamlit.io/)
- [Dataset: Air Pollution in Seoul (Kaggle)](https://www.kaggle.com/datasets/bappekim/air-pollution-in-seoul)

---
